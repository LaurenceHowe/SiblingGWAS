#ARGUMENTS
#1) Path of .bgen files (data.chr{i}.bgen)
#2) File containing sibling IDs for filtering (Siblings.txt)

#Requirements
#1) Plink 1.90
#2) QCtool
#3) R

# First copy your sample file to a new file
cp data.sample filtered.sample

# If you need to filter out samples you need to generate a new sample file.
 
In R:
 d<-read.table("data.sample",header=T,stringsAsFactors=F)
 e<-read.table("exclusion.samples.txt",stringsAsFactors=F)
 d2<-d[(which(d[,1]%in%e[,1]==F)),]
 write.table(d2,"filtered.sample",sep=" ",col.names=T,row.names=F,quote=F)


#!/bin/bash
for i in {1..22}
do

#Extract siblings
qctool -g data.chr${i}.bgen -s data.chr1-22.sample -incl-samples Siblings.txt -og filteredchr${i}.bgen

#Calculate summary data (INFO scores etc)
qctool -g filteredchr${i}.bgen -s filtered.sample -snp-stats -osnp data_chr${i}.snp-stats

#Extract best-guess data
plink --bgen filteredchr${i}.bgen --sample filtered.sample --set-missing-var-ids @:#\$1,\$2 --make-bed --out data_chr${i}_filtered --hard-call-threshold 0.499999

# Rename the SNP IDs if necessary to avoid possible duplicates
cp data_chr${i}_filtered.bim data_chr${i}_filtered.bim.orig

awk '{
if (($5 == "A" || $5 == "T" || $5 == "C" || $5=="G") &&  ($6 == "A" || $6 == "T" || $6 == "C" || $6=="G"))
   print $1, "chr"$1":"$4":SNP", $3, $4, $5, $6;
else
   print $1, "chr"$1":"$4":INDEL", $3, $4, $5, $6;
     }' data_chr${i}_filtered.bim.orig > data_chr${i}_filtered.bim

# For simplicity remove any duplicates
cp data_chr${i}_filtered.bim data_chr${i}_filtered.bim.orig2
awk '{
     if (++dup[$2] > 1) {
            print $1, $2".duplicate."dup[$2], $3, $4, $5, $6
     } else {
       print $0 }
    }' data_chr${i}_filtered.bim.orig2 > data_chr${i}_filtered.bim
grep "duplicate" data_chr${i}_filtered.bim | awk '{ print $2 }' > duplicates.chr${i}.txt

plink --bfile data_chr${i}_filtered --exclude duplicates.chr${i}.txt --make-bed --out data_chr${i}_filtered_2

mv data_chr${i}_filtered_2.bed data_chr${i}_filtered.bed
mv data_chr${i}_filtered_2.bim data_chr${i}_filtered.bim
mv data_chr${i}_filtered_2.fam data_chr${i}_filtered.fam

# Relabel the SNP IDs and extract relevant columns in the snp-stats file
# Assumes column 4 is the position
# Assumes columns 5 and 6 are the allele names
# Assumes column 14 is the MAF
# Assumes columns 17 is the info score

#Remove lines with #

sed -i '/#/d' data_chr${i}.snp-stats

awk -v chr=$i '{
       if (($5 == "A" || $5 == "T" || $5 == "C" || $5=="G") &&  ($6 == "A" || $6 == "T" || $6 == "C" || $6=="G"))
            print "chr"chr":"$4":SNP", $14, $17;
            else
            print "chr"chr":"$4":INDEL", $14, $17;
            }' data_chr${i}.snp-stats > data_chr${i}.info


# Remove duplicates from snp-stats
cp data_chr${i}.info data_chr${i}.info.orig
awk '{
        if (++dup[$1] > 1) {
            print $1".duplicate."dup[$1], $2, $3
        } else {
            print $0 }
}' data_chr${i}.info.orig > data_chr${i}.info
fgrep -v -w -f duplicates.chr${i}.txt <data_chr${i}.info >chr${i}_filtered.info
done

for i in {2..22}
do 
    echo "data_chr${i}_filtered"
done > mergefile.txt

plink --bfile data_chr1_filtered --merge-list mergefile.txt --make-bed --out temp

# Combine info files into a single file

head -n1 chr01_filtered.info > data_filtered.info

for i in {1..22}
do
    awk ' NR>1 {print $0}' < chr${i}_filtered.info |cat >> data_filtered.info
done


# Prune on INFO 0.8 and MAF 0.01

awk '$2<0.01 || $3<0.3  {print $1}' data_filtered.info > remove.txt

plink --bfile temp --exclude remove.txt --make-bed --out data_filtered

rm temp*
